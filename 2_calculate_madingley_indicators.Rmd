---
title: "Visualising different data smoothing options for the RLI"
author: "Simone Stevenson"
date: "08/09/2021"
output:
  pdf_document: default
  html_document: default
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set( echo=FALSE,results='hide',fig.keep='all', message = FALSE,
  comment = '', fig.width = 6, fig.height = 6
)
```

```{r packages and functions}

rm(list = ls())

## Data wrangling

library(tidyverse)
library(rlist)
library(zoo)

## Data visualisation

library(ggridges)
library(cowplot)
library(ggThemeAssist)

# Functions ----

# Function to replace any non-extinct status following an extinction
# classification (resulting from juveniles growing into that massbin)
# with extinction
# https://stackoverflow.com/questions/45284226/how-to-replace-values-after-a-specific-event-in-a-data-frame

maintain_ex_status <- function(vec) { 
  vec_len = length(vec) 
  first_ex = match("EX", vec, nomatch = vec_len) 
  if(first_ex < vec_len) replace(vec, (first_ex+1):vec_len, "EX") 
  else vec 
}

# Similar function but replaces all non 0 values that occur after the first 
# 0 with 0

maintain_0_abundance <- function(vec) { 
  vec_len = length(vec) 
  first_0 = match(0, vec, nomatch = vec_len) 
  if(first_0 < vec_len) replace(vec, (first_0+1):vec_len, 0) 
  else vec 
}

# Scale values between 0 and 1

range01 <- function(x){(x-min(x, na.rm = TRUE))/(max(x, na.rm = TRUE)-min(x, na.rm = TRUE))}

# data <- rli_inputs
# numboots <- 5
# Function to calculate RLI

#' Calculate the RLI over time, from a dataframe of species and their 
#' IUCN Red List Categories 

#' @param data a data frame (should be named red list inputs) with columns:
#' group_id (representing functional group-massbin pseudo species), time_step
#' abundance, generation_length_yrs, "functional_group_index", "functional_group_name"
#' "mass_lower_g", "mass_upper_g", "massbin_g", timeframe, "diff" , "decline",
#' "rl_status",  "extinct", "rl_status"
#' @param numboots an integer representing the number of bootstraps to calculate
#' @param ci logical, do you want to include confidence intervals? default = FALSE
#' (note, selecting TRUE may increase processing time)
#' @return a dataframe of RLI index scores and confidence intervals over time

#data <- scenario_red_list_inputs_annual[[1]][[1]]

calculate_red_list_index <- function(data, numboots, ci = FALSE, replicate_num = NA){
  
  # Using equation from Butchart et al (2007) Improvements to the Red List Index
  
  require(tidyverse)
  
  # Remove data without RL status
  
  #data$redlist_assessment_year <- as.numeric(as.character(data$redlist_assessment_year))
  
  data <- data %>%
          filter(!is.na(rl_status)) %>%
          group_by(group_id) 
  
  head(data)
  
  # ecoregion <- as.factor(data$ecoregion_id[1])
  
  # Assign category weights
  
  weighted_data <- data %>%
    dplyr::mutate(rl_weight = ifelse(rl_status == "LC", 0,
                              ifelse(rl_status == "NT", 1,
                              ifelse(rl_status == "VU", 2,
                              ifelse(rl_status == "EN", 3,
                              ifelse(rl_status == "CR", 4,
                              ifelse(rl_status == "EX", 5, NA))))))) 
  head(weighted_data)
  dim(weighted_data)
 
  
  #weighted_data$RL_weight <- as.numeric(as.character(weighted_data$RL_weight))
  
  # Filter out rows with NE and DD
  weighted_data <- weighted_data %>%
                   filter(rl_status != "NE") %>%
                   filter(rl_status != "DD") %>%
                   filter(rl_status != "NA")
  
  dim(weighted_data)
  
  # Group data so the index is calculated for each functional group 
  # (would normally be taxa) for each year. If you run on a single group
  # it shouldn't matter, will just turn data into one big group
  
  grouped_data <- weighted_data %>% group_by(functional_group_name, annual_time_step)
  
  # Sum category weights for each group, in each timestep,
  # calculate number of species per group
  summed_weights <- summarise(grouped_data, 
                              total_weight = sum(rl_weight, na.rm = TRUE), # calc sum of all weights
                              total_count = n(),# calc number of species
                              .groups = "drop_last") %>%
                    mutate(total_count = max(total_count))  # Fix so it takes total number at beginning, otherwise n fluctuates between timesteps
  
  # Calculate RLI scores for each group, rounded to 3 decimal places
  
  index_scores <- summed_weights %>%
    mutate(RLI = 1 - (total_weight/(total_count * 5)), # actual RLI formula
           Criteria = "risk")

  if (ci == TRUE) {
  # Calculate confidence intervals via bootstrapping 
  # (see Rowland et al 2021 A guide to representing uncertainty)
  
  # Split by timestep - we want CI for each functional group, for each timestep 
  
  weighted_data_timestep_list <- split(weighted_data, weighted_data$annual_time_step)
  
  ## For each functional group (level 1)

  timestep_confidence_intervals <- list()
  
  for (i in seq_along(weighted_data_timestep_list)) {
    
    # Get single time-step then group by functional group
    
      grouped_timestep_data <- weighted_data_timestep_list[[i]] %>%
                             group_by(functional_group_name)
    
      time <- grouped_timestep_data$annual_time_step[1]
    
      boot <- list()
     # Calculate the bootstrap confidence intervals
      for (k in 1:numboots) {
        
        # Take k number of random samples from the weighted data
        replicate <- slice_sample(grouped_timestep_data, 
                                  prop = 1, replace = TRUE) %>%  # get random sample of rows and add to DF
                     mutate(replicate = k)
                   # label each replicate
        
        boot[[k]] <- replicate
        # Combine replicates into one dataframe
        
       # print(paste("Bootstrap", k, "of", numboots, "complete", sep =" "))
        
      }
    
      boot_reps <- do.call(rbind, boot)
      
      # Group by replicate
      #replicate_data <- group_by(boot_reps, replicate) # Group by replicate
        
      # Calculate the summary values needed to calc RLI for each replicate
      summed_weights_timestep_fg <- boot_reps %>%
                                    group_by(functional_group_name,replicate) %>% 
                                    summarise(total_weight = sum(rl_weight, na.rm = TRUE), # calc sum of all weights
                                              total_count = n(),# calc number of species
                                              .groups = "drop_last") %>%
                                    mutate(total_count = max(total_count))
        
      # Calculate the RLI score for each replicate
      rep_scores <- mutate(summed_weights_timestep_fg, 
                             RLI = 1 - (total_weight/(total_count * 5))) # actual RLI formula
        
      # Calculate the confidence intervals for each fg,
      ci_scores <- summarise(rep_scores, 
                               ci_lower = quantile(rep_scores$RLI, 
                                                   probs = 0.025),
                               ci_upper = quantile(rep_scores$RLI, 
                                                   probs = 0.975)) %>%
                   mutate(annual_time_step = time) 
      
      timestep_confidence_intervals[[i]] <- ci_scores
    
  }
  
  confidence_intervals <- do.call(rbind, timestep_confidence_intervals)
  
  red_list_scores <- index_scores %>%
                     merge(confidence_intervals, 
                           by = c("functional_group_name",
                                   "annual_time_step")) %>%
                     dplyr::select(functional_group_name, annual_time_step, ci_lower,
                                    RLI, ci_upper, everything()) %>% 
                     rename(indicator_score = RLI) %>% 
                     mutate(indicator = "RLI",
                            replicate = replicate_num)
                      
  
  return(red_list_scores)
  
  } else {
    
 red_list_scores <- index_scores  %>% 
                    rename(indicator_score = RLI) %>% 
                    mutate(indicator = "RLI",
                            replicate = replicate_num,
                            ci_lower = NA,
                            ci_upper = NA) %>% 
                    dplyr::select(functional_group_name, annual_time_step,
                                  ci_lower, indicator_score, ci_upper, total_weight,
                                  total_count, Criteria, indicator, replicate) 
                    
 
 return(red_list_scores)
 
    }
}

# For all taxa at once

# data <- scenario_redlist_data_sampled[[2]]

calculate_red_list_index2 <- function(data, numboots, ci = FALSE, replicate_num = NA){
  
  # Using equation from Butchart et al (2007) Improvements to the Red List Index
  
  require(tidyverse)
  
  # Remove data without RL status
  
  #data$redlist_assessment_year <- as.numeric(as.character(data$redlist_assessment_year))
  
  data <- data %>%
    filter(!is.na(rl_status)) %>%
    group_by(group_id) 
  
  head(data)
  
  # ecoregion <- as.factor(data$ecoregion_id[1])
  
  # Assign category weights
  
  weighted_data <- data %>%
    dplyr::mutate(rl_weight = ifelse(rl_status == "LC", 0,
                                     ifelse(rl_status == "NT", 1,
                                            ifelse(rl_status == "VU", 2,
                                                   ifelse(rl_status == "EN", 3,
                                                          ifelse(rl_status == "CR", 4,
                                                                 ifelse(rl_status == "EX", 5, NA))))))) 
  head(weighted_data)
  dim(weighted_data)
  
  
  #weighted_data$RL_weight <- as.numeric(as.character(weighted_data$RL_weight))
  
  # Filter out rows with NE and DD
  weighted_data <- weighted_data %>%
    filter(rl_status != "NE") %>%
    filter(rl_status != "DD") %>%
    filter(rl_status != "NA")
  
  dim(weighted_data)
  
  # Group data so the index is calculated for each functional group 
  # (would normally be taxa) for each year. If you run on a single group
  # it shouldn't matter, will just turn data into one big group
  
  grouped_data <- weighted_data %>% group_by(annual_time_step)
  
  # Sum category weights for each group, in each timestep,
  # calculate number of species per group
  summed_weights <- summarise(grouped_data, 
                              total_weight = sum(rl_weight, na.rm = TRUE), # calc sum of all weights
                              total_count = n(),# calc number of species
                              .groups = "drop_last") %>%
    mutate(total_count = max(total_count))  # Fix so it takes total number at beginning, otherwise n fluctuates between timesteps
  
  # Calculate RLI scores for each group, rounded to 3 decimal places
  
  index_scores <- summed_weights %>%
    mutate(RLI = 1 - (total_weight/(total_count * 5)), # actual RLI formula
           Criteria = "risk")
  
  if (ci == TRUE) {
    # Calculate confidence intervals via bootstrapping 
    # (see Rowland et al 2021 A guide to representing uncertainty)
    
    # Split by timestep - we want CI for each functional group, for each timestep 
    
    weighted_data_timestep_list <- split(weighted_data, weighted_data$annual_time_step)
    
    ## For each functional group (level 1)
    
    timestep_confidence_intervals <- list()
    
    for (i in seq_along(weighted_data_timestep_list)) {
      
      # Get single time-step then group by functional group
      
      grouped_timestep_data <- weighted_data_timestep_list[[i]] %>%
        group_by(functional_group_name)
      
      time <- grouped_timestep_data$annual_time_step[1]
      
      boot <- list()
      # Calculate the bootstrap confidence intervals
      for (k in 1:numboots) {
        
        # Take k number of random samples from the weighted data
        replicate <- slice_sample(grouped_timestep_data, 
                                  prop = 1, replace = TRUE) %>%  # get random sample of rows and add to DF
          mutate(replicate = k)
        # label each replicate
        
        boot[[k]] <- replicate
        # Combine replicates into one dataframe
        
        # print(paste("Bootstrap", k, "of", numboots, "complete", sep =" "))
        
      }
      
      boot_reps <- do.call(rbind, boot)
      
      # Group by replicate
      #replicate_data <- group_by(boot_reps, replicate) # Group by replicate
      
      # Calculate the summary values needed to calc RLI for each replicate
      summed_weights_timestep_fg <- boot_reps %>%
        group_by(functional_group_name,replicate) %>% 
        summarise(total_weight = sum(rl_weight, na.rm = TRUE), # calc sum of all weights
                  total_count = n(),# calc number of species
                  .groups = "drop_last") %>%
        mutate(total_count = max(total_count))
      
      # Calculate the RLI score for each replicate
      rep_scores <- mutate(summed_weights_timestep_fg, 
                           RLI = 1 - (total_weight/(total_count * 5))) # actual RLI formula
      
      # Calculate the confidence intervals for each fg,
      ci_scores <- summarise(rep_scores, 
                             ci_lower = quantile(rep_scores$RLI, 
                                                 probs = 0.025),
                             ci_upper = quantile(rep_scores$RLI, 
                                                 probs = 0.975)) %>%
        mutate(annual_time_step = time) 
      
      timestep_confidence_intervals[[i]] <- ci_scores
      
    }
    
    confidence_intervals <- do.call(rbind, timestep_confidence_intervals)
    
    red_list_scores <- index_scores %>%
      merge(confidence_intervals, 
            by = c("functional_group_name",
                   "annual_time_step")) %>%
      dplyr::select(functional_group_name, annual_time_step, ci_lower,
                    RLI, ci_upper, everything()) %>% 
      rename(indicator_score = RLI) %>% 
      mutate(indicator = "RLI",
             replicate = replicate_num)
    
    
    return(red_list_scores)
    
  } else {
    
    red_list_scores <- index_scores  %>% 
      rename(indicator_score = RLI) %>% 
      mutate(indicator = "RLI",
             replicate = replicate_num,
             ci_lower = NA,
             ci_upper = NA) %>% 
      dplyr::select(annual_time_step,
                    ci_lower, indicator_score, ci_upper, total_weight,
                    total_count, Criteria, indicator, replicate) 
    
    
    return(red_list_scores)
    
  }
}

#' Return a line plot of the RLI scores over time faceted by functional group 

#' @param data a data frame (output from calculate_red_list_index) with columns:
#' functional_group, time_step, ci_lower, ci_upper, total.weight, total.count, RLI criteria
#' @param impact_start time_step impact began
#' @param impact_end time_step impact ended
#' @param ci logical, do you want to include confidence intervals? default = FALSE
#' (note, selecting TRUE may increase processing time)
#' @return a line plot of RLI over time for each functional group/taxa or whatever 
#' 
# data <- scenario_rli_outputs[[1]][[1]]

plot_red_list_index_by_group <- function(data, impact_start, impact_end, ci = FALSE) {
  
  require(ggplot2)
  require(viridis)
  
  if (ci == TRUE) {
  
  plot <- ggplot(data = data, aes(x = annual_time_step, y = indicator_score,
                           group = functional_group_name,
                           fill = functional_group_name)) +
    geom_line(aes(colour = functional_group_name)) +
    geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper),
                alpha = 0.4) +
    scale_fill_viridis_c() +
    scale_color_viridis_c() + 
    facet_wrap(~functional_group_name) +
    labs(x = "Time", 
         y = "Red List Index Score") +
    scale_y_continuous(limits = c(0,1)) +
    theme(panel.grid.major = element_blank(),
          axis.title = element_text(size = 18),
          axis.text = element_text(size = 18),
          panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "grey97"),
          axis.line = element_line(colour = "black"),
          legend.position = "none") +
    geom_vline(xintercept = impact_start, colour = "red") +
    geom_vline(xintercept = impact_end, colour = "blue")
  
  return(plot)
  
  } else {
    
    plot <- ggplot(data = data, aes(x = annual_time_step, y = indicator_score,
                                    group = functional_group_name,
                                    fill = functional_group_name)) +
      geom_line(aes(color = functional_group_name)) +
      scale_fill_viridis_d() +
      scale_color_viridis_d() + 
      facet_wrap(~functional_group_name) +
      labs(x = "Time", 
           y = "Red List Index Score") +
      scale_y_continuous(limits = c(0,1)) +
      theme(panel.grid.major = element_blank(),
            axis.title = element_text(size = 18),
            axis.text = element_text(size = 18),
            panel.grid.minor = element_blank(),
            panel.background = element_rect(fill = "grey97"),
            axis.line = element_line(colour = "black"),
            legend.position = "none") +
      geom_vline(xintercept = impact_start, colour = "red") +
      geom_vline(xintercept = impact_end, colour = "blue")
    
    return(plot)
    
  }

}

#' Return a line plot of the RLI scores over time for a single group 

#' @param data a data frame (output from calculate_red_list_index) with columns:
#' functional_group, time_step, ci_lower, ci_upper, total.weight, total.count, RLI criteria
#' @param impact_start time_step impact began
#' @param impact_end time_step impact ended
#' #' @param ci logical, do you want to include confidence intervals? default = FALSE
#' (note, selecting TRUE may increase processing time)
#' @return a line plot of RLI over time for each functional group/taxa or whatever 

plot_red_list_index <- function(data, impact_start, impact_end, ci = FALSE, raw) {
  
  require(ggplot2)
  require(viridis)
  
  if (ci == TRUE) {
  
  plot <- ggplot() +
    geom_line(data = data, aes(x = annual_time_step, y = indicator_score)) +
    geom_point(data = raw, aes(x = annual_time_step, y = indicator_score),
               alpha = 0.2, col = "turquoise", fill = "turquoise") +
    geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper),
                alpha = 0.4) +
    #scale_fill_viridis_d() +
    #scale_color_viridis_d() + 
    labs(x = "Time", 
         y = "Red List Index Score") + 
    scale_y_continuous(limits = c(0,1)) +
    theme(panel.grid.major = element_blank(),
          axis.title = element_text(size = 18),
          axis.text = element_text(size = 18),
          panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "grey97"),
          axis.line = element_line(colour = "black"),
          legend.position = "none") +
    geom_vline(xintercept = impact_start, colour = "red") +
    geom_vline(xintercept = impact_end, colour = "blue")
  
  return(plot)
  
  } else {
    
    plot <- ggplot() +
      geom_line(data = data, aes(x = annual_time_step, y = indicator_score)) +
    geom_point(data = raw, aes(x = annual_time_step, y = indicator_score),
               alpha = 0.2, col = "turquoise", fill = "turquoise") +
      # scale_fill_viridis_d() +
      # scale_color_viridis_d() + 
      labs(x = "Time", 
           y = "Red List Index Score") + 
      scale_y_continuous(limits = c(0,1)) +
      theme(panel.grid.major = element_blank(),
            axis.title = element_text(size = 18),
            axis.text = element_text(size = 18),
            panel.grid.minor = element_blank(),
            panel.background = element_rect(fill = "grey97"),
            axis.line = element_line(colour = "black"),
            legend.position = "none") +
      geom_vline(xintercept = impact_start, colour = "red") +
      geom_vline(xintercept = impact_end, colour = "blue")
    
    return(plot)
  }
  
}

#' @param data a data frame with columns 'group id', 'time_step', 'abundance'
#' @param numboots an integer representing the number of bootstraps to calculate
#' @param ci logical, do you want to include confidence intervals? default = FALSE
#' (note, selecting TRUE may increase processing time)
#' @param replicate_num numeric/character identifier if calculating for more than one replicate
#' @return a dataframe of LPI index scores and confidence intervals over time

## Note: Have tested this code against the code Emily used on the LME ecopath
## data to see if they produce the same results, which they do.

#data <- scenario_lpi_inputs[[1]][[1]]

calculate_living_planet_index <- function(data, start_time_step = 1, ci = FALSE,
                                          numboots, replicate_num = NA){
  
  filtered_inputs <- data %>%
    rename(ave_abundance = abundance) %>% 
    # Remove timesteps if needed (if not make start_time_step = 1)
    filter(annual_time_step >= start_time_step) %>%
    # Group by virtual species (vs)
    group_by(group_id) %>% 
    # Remove vs that have no individuals at any timestep
    filter(!all(ave_abundance == 0)) %>% 
    # Save a copy of original abundance values
    # rename(abundance_original = abundance) %>%
    # Identify rows where abundance == 0, and change all subsequent years to 0 too
    # mutate(abundance = maintain_0_abundance(abundance_original)) 
    mutate(abundance = ave_abundance) %>% 
    dplyr::select(-ave_abundance)
  
  head(filtered_inputs)
  
  # Calculate LPI inputs and LPI
  ## Based on McRae, L., Loh. J., Bubb, P.J., Baillie, J.E.M., Kapos, V.,
  ## and Collen, B. 2008. The Living Planet Index - Guidance for
  ## National and Regional Use. UNEP-WCMC, Cambridge, UK.
  
  lpi_inputs <- filtered_inputs %>%
                # Calculate 1% of the mean population over time for each group
                group_by(group_id) %>%
                # Add 1% of the species mean abundance across all timesteps
                # so we can take the log in the next step
                mutate(abundance_adjusted = abundance +
                         (mean(abundance, na.rm = TRUE)*0.01)) %>%
                # Calculate the rate of change since the previous year (dt)
                # (equation 1 in Mcrae et al 2008)
                mutate(current_abundance = abundance_adjusted, #abundance at current timestep
                       previous_abundance = lag(abundance_adjusted, 1)) %>%  #abundance at previous timestep
                mutate(dt = log10(current_abundance/previous_abundance)) %>% # rate of change
                ungroup(.) %>%
                # Calculate mean dt across all groups, per timestep
                # (equation 4 in Mcrae et al 2008)
                group_by(annual_time_step) %>%
                summarise(mean_dt = mean(dt, na.rm = TRUE),
                          sd = sd(dt, na.rm = TRUE)) %>%
                # Add an empty LPI column to fill up in the next step
                mutate(LPI = NA)
  
  # Set the value of the LPI on the first time step to 1
  lpi_inputs$LPI[start_time_step] <- 1 

  # Annoyingly can't get a dplyr version of this to work, but whatever
  
       for (i in 1:(nrow(lpi_inputs) - 1)) {
         
         # T represents the current timestep we are calculating for, i represents
         # the previous timestep
         t <- i + 1
         
         # Multiple the LPI score from the previous timestep i by ten to the
         # power of dt in the current timestep t
         # Equation 5 in Mcrae et al 2008
         
         lpi_inputs$LPI[t] <- lpi_inputs$LPI[i] * (10 ^ lpi_inputs$mean_dt[t])
        
       
         }
  
  if(ci == TRUE) {
  # Now calculate the confidence intervals using bootstrapping as per 
  # Rowland et al 2021
  
  # Create n replicates of the original data (same number of rows but randomly
  # sampled, and with replacement)
  
  bootstrap_replicates <- list()
  
  for (j in 1:numboots) {
  
  # Make sure we get the same sample every time for reproducibility
    
  set.seed(j)
    
  # Produce a replicate dataset that is randomly sampled from the original 
  # dataset but with replacement
  
  rep <- filtered_inputs %>% 
         group_by(annual_time_step) %>% # so we take random samples stratified by timestep (otherwise end up with uneven sample sizes in each timestep)
         slice_sample(prop = 1, replace = TRUE) %>%  # get random sample of rows and add to DF
         mutate(replicate = j)
  
  # Calculate the mean rate of change across species
  
  rep_lpi_inputs <- rep %>%
    # Calculate 1% of the mean population over time for each group
    group_by(group_id) %>%
    # Add 1% of the species mean abundance across all timesteps 
    # so we can take the log in the next step
    mutate(abundance_adjusted = abundance + 
             (mean(abundance)*0.01)) %>%
    # Calculate the rate of change since the previous year (dt)
    # (equation 1 in Mcrae et al 2008) 
    mutate(current_abundance = abundance_adjusted, #abundance at current timestep
           previous_abundance = lag(abundance_adjusted, 1)) %>%  #abundance at previous timestep
    mutate(dt = log10(current_abundance/previous_abundance)) %>% # rate of change
    ungroup(.) %>% 
    # Calculate mean dt across all groups, per timestep
    # (equation 4 in Mcrae et al 2008)
    group_by(annual_time_step) %>% 
    summarise(mean_dt = mean(dt, na.rm = TRUE)) %>% 
    # Add an empty LPI column to fill up in the next step
    mutate(LPI = NA,
           replicate = j)
  
  # Set the value of the LPI on the first time step to 1
  rep_lpi_inputs$LPI[start_time_step] <- 1 
  
  # Calculate the LPI
  # Annoyingly can't get a dplyr version of this to work, but whatever
  
  for (i in 1:(nrow(rep_lpi_inputs) - 1)) {
    
    # T represents the current timestep we are calculating for, i represents
    # the previous timestep
    t <- i + 1
    
    # Multiple the LPI score from the previous timestep i by ten to the
    # power of dt in the current timestep t
    # Equation 5 in Mcrae et al 2008
    
    rep_lpi_inputs$LPI[t] <- rep_lpi_inputs$LPI[i] * (10 ^ rep_lpi_inputs$mean_dt[t])
    
    print(paste("bootstrap", j, "of", numboots, "complete", sep = " "))
    
  }
  
  bootstrap_replicates[[j]] <- rep_lpi_inputs
  
  }
  
  # Bind all the replicates into one DF
  
  bootstrap_replicates_df <- do.call(rbind, bootstrap_replicates)
  
  # Get the confidence intervals for each timestep
  
  ci_scores <- bootstrap_replicates_df %>% 
               group_by(annual_time_step) %>% # Get the LPI scores for all reps, for each timestep
               summarise(ci_lower = quantile(LPI,
                                             probs = 0.025), # Get the lower quantile of all LPI rep scores
                         ci_upper = quantile(LPI,
                                             probs = 0.975)) # Get the upper quantile
     
  # Merge the confidence intervals with the original LPI
  
  index_scores <- lpi_inputs %>% 
                  merge(ci_scores, by = "annual_time_step") %>% 
                  select(annual_time_step, LPI, ci_lower, ci_upper) %>% 
                  mutate(indicator = "LPI",
                         replicate = replicate_num) %>% 
                  rename(indicator_score = LPI)
  
  } else {
    
  index_scores <- lpi_inputs %>% 
    select(annual_time_step, LPI) %>%
    mutate(indicator = LPI,
           replicate = replicate_num,
           ci_lower = NA,
           ci_upper = NA) %>%
    rename(indicator_score = LPI)
  
  }
  
  return(index_scores)
 
}

# x <- calculate_living_planet_index(data, 1, FALSE, 1, "test")
# head(x)

#' @param data a data frame with columns 'time_step', 'mean_dt', 'LPI',
#' 'ci_lower' and 'ci_upper'
#' @param ci logical, do you want to plot confidence intervals? default = FALSE
#' (note, selecting TRUE may increase processing time)
#' @return a dataframe of LPI index scores and confidence intervals over time
#' 
plot_living_planet_index <- function(data, ci = FALSE) {
  
  if (ci == TRUE) {
  
    ggplot(data, aes(x = annual_time_step, y = indicator_score)) +
    geom_line()  +
    scale_y_continuous(limits = c(0,3)) +
    geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper),
                    alpha = 0.4)
  } else {
    
    ggplot(data, aes(x = annual_time_step, y = indicator_score)) +
      geom_line() +
      scale_y_continuous(limits = c(0, 3))
    
  }
}

# lpi <- calculate_living_planet_index(data, start_time_step = 1, ci = TRUE,
#                                      numboots = 1000)
# plot_living_planet_index(lpi, ci = TRUE)
```

# Prep data

```{r load inputs and data}

# Set up paths ----

if (Sys.info()['nodename'] == "SIMONE-PC") {
  
  SourceToModels <- 'C:/Users/Simone/Dropbox/Deakin/Serengeti-analysis'
  IndicatorsProject <- "N:/Quantitative-Ecology/Indicators-Project"
  
}  

if (Sys.info()['nodename'] == "ANALYTIX2") {
  
  SourceToModels <- "C:/Users/ssteven/Desktop/Serengeti-analysis"
  IndicatorsProject <- "N:/Quantitative-Ecology/Indicators-Project"
}

if (Sys.info()['nodename'] == "20FMPC0C6GH9") {
  
  SourceToModels <- "C:/Users/ssteven/Dropbox/Deakin/Serengeti-analysis"
  IndicatorsProject <- "N:/Quantitative-Ecology/Indicators-Project"
}

if (Sys.info()['nodename'] == "80VVPF0SSB53") {
  
  SourceToModels <- 'K:/BiodiversityIndicators/serengeti'
  IndicatorsProject <- "N:/Quantitative-Ecology/Indicators-Project"
}

# Inputs ----

# disable scientific notation

options(scipen = 999)

# Get date to label outputs

input_date <- "2021-09-09"

today <- Sys.Date()

# Define mode (development == TRUE will only perform operations on a small subset
# of folders, not all outputs)

development_mode <- FALSE

# Specify universal input arguments

if (development_mode == FALSE) {
  

  burnin_months <- 1000*12 # in months
  n <- 12
  numboots <- 1000 # Rowland et al 2021 (uncertainty)
  start_time_step <- 1
  gen_timeframe <- 10 
  interval <- 12 
  # Don't adjust these
  max_timestep <- 300/(interval/12)
  impact_start <- max_timestep/3 * 1  #in years
  impact_end <- max_timestep/3 * 2  #in years
  
} else {
  

  burnin_months <- 1000*12 # in months
  n <- 12
  numboots <- 2 # Rowland et al 2021 (uncertainty)
  start_time_step <- 1
  gen_timeframe <- 10 # in years
  interval <- 12 
  # Don't adjust these
  max_timestep <- 300/(interval/12)
  impact_start <- max_timestep/3 * 1  #in years
  impact_end <- max_timestep/3 * 2  #in years
  
}

indicators_project <- IndicatorsProject # File path for entire project directory

location <- 'Serengeti'

# Set up output folders

indicator_inputs_folder <- file.path(indicators_project, 
                           "/Serengeti/Outputs_from_indicator_code/Indicator_inputs")

if( !dir.exists( file.path(indicator_inputs_folder) ) ) {
  dir.create( file.path(indicator_inputs_folder), recursive = TRUE )
  
}

indicator_outputs_folder <- file.path(indicators_project, 
                                     "/Serengeti/Outputs_from_indicator_code/Indicator_outputs")

if( !dir.exists( file.path(indicator_outputs_folder) ) ) {
  dir.create( file.path(indicator_outputs_folder), recursive = TRUE )
  
}

indicator_plots_folder <- file.path(indicators_project, 
                                     "/Serengeti/Outputs_from_indicator_code/Indicator_plots")

if( !dir.exists( file.path(indicator_plots_folder) ) ) {
  dir.create( file.path(indicator_plots_folder), recursive = TRUE )
  
}

# Load data
scenario_ab_gl_formatted <- readRDS(file.path(indicator_outputs_folder, paste(input_date,
                                       "formatted_abundance_1.rds", 
                                       sep = "_")))

scenario_decomposed <- readRDS(file.path(indicator_outputs_folder,paste(input_date,
                                       "decomposed_abundance_2.rds", 
                                       sep = "_")))

scenario_averaged <- readRDS(file.path(indicator_outputs_folder,paste(input_date,
                                       "averaged_abundance_3.rds", 
                                       sep = "_")))

scenario_filtered <- readRDS(file.path(indicator_outputs_folder,paste(input_date,
                                       "weird_groups_removed_abundance_4.rds", 
                                       sep = "_")))

scenario_smoothed_abundance <- readRDS(file.path(indicator_outputs_folder,paste(input_date,
                                       "smoothed_abundance_5.rds", 
                                       sep = "_")))

scenario_harvested <- readRDS(file.path(indicator_outputs_folder,paste(input_date,
                                       "scenario_density_harvested.rds", sep = "_")))

# scenario_smoothed_5 <- readRDS(file.path(indicator_outputs_folder,paste(input_date,
#                                        "scenario_smoothed_abundance_5.rds", sep = "_")))

scenarios <- c("Baseline", "Land use", "Harvesting carnivores", "Harvesting herbivores")

```

# RAW vs TRUNCATED (80th percentile) & DECOMPOSED DATA
Using a random replicate and harvested group, show the change in data over
each processing step (number of step represents order in process)

```{r Raw v Truncated }

# Plot data transformation ----

## Get an example group for each scenario (random for baseline, mid size herb for land use,
## big carn for carnivores, big herb for herbivores)
example_group <- c("10.59", "10.40", "11.68", "10.68")

# Raw abundance
r <- 1 # Pick a replicate

## * Decomposition ----

### Plot the change from raw data to truncated and decomposed


decomposition_plots <- list()

for ( i in seq_along(scenario_ab_gl_formatted)) {

group_raw <- scenario_ab_gl_formatted[[i]][[r]] %>% 
             filter(group_id == example_group[[i]]) %>% 
             mutate(data_processing_level = "1 - raw for single replicate")

# Decomposed abundance

group_decomposed <- scenario_decomposed[[i]][[r]] %>% 
                    filter(group_id == example_group[[i]]) %>% 
                    mutate(data_processing_level = "2 - 80th percentile & decomposed for single replicate")

plot_data <- rbind(group_raw, group_decomposed)

decomposition_plots[[i]] <- ggplot(data = plot_data, aes(x = monthly_time_step, 
                                                         y = abundance,
                                                         col = data_processing_level)) +
  geom_point() +
  scale_color_manual(values = c("light blue", "pink")) +
  theme(panel.grid.major = element_line(linetype = "blank"), 
        panel.grid.minor = element_line(linetype = "blank"), 
        panel.background = element_rect(fill = "gray49"),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        legend.position = "bottom") +
  labs(title = scenarios[[i]])

rm(group_raw, group_decomposed, plot_data)

}

decomposition_plots[[1]]
decomposition_plots[[2]]
decomposition_plots[[3]]
decomposition_plots[[4]]

```

# SMOOTHED VS UNSMOOTHED DATA 

Averaged across replicates, for a harvested group

```{r RLI smoothed v unsmoothed }

smoothing_plots <- list()

for ( i in seq_along(scenario_averaged)) {
  
  group_decomposed <- scenario_decomposed[[i]][[r]] %>% 
    filter(group_id == example_group[[i]]) %>% 
    mutate(data_processing_level = "2 - 80th percentile & decomposed for one replicate")
  
  # Compare to averaged (not smoothed)
  group_averaged <- scenario_averaged[[i]] %>% 
    filter(group_id == example_group[[i]]) %>% 
    mutate(data_processing_level = "3 - Averaged across replicates")
  
  # Compare to averaged and false extinctions gone
  group_smoothed <- scenario_smoothed_abundance[[i]] %>% 
    filter(group_id == example_group[[i]]) %>% 
    mutate(data_processing_level = "4 - Smoothed over five year rollin window") %>% 
    dplyr::select(-abundance) %>% 
    rename(abundance = ave_abundance)
  
  plot_data <- rbind(group_decomposed, group_averaged, group_smoothed)

  smoothing_plots[[i]] <-  ggplot() +
    geom_point(data = plot_data, aes(x = monthly_time_step, 
                                     y = abundance,
                                     col = data_processing_level),
               alpha = 0.2) +
    scale_color_manual(values = c("light blue", "purple", "yellow")) +
    theme(panel.grid.major = element_line(linetype = "blank"), 
          panel.grid.minor = element_line(linetype = "blank"), 
          panel.background = element_rect(fill = "gray49"),
          axis.text.y=element_blank(),
          axis.ticks.y=element_blank(),
          legend.position = "bottom") +
    labs(title = scenarios[[i]])
  
  
  rm(group_smoothed, group_averaged, plot_data, group_decomposed)
  
}

smoothing_plots[[1]]
smoothing_plots[[2]]
smoothing_plots[[3]]
smoothing_plots[[4]]

```

# RED LIST INDEX ANNUAL V1

Calculating RLI for the functional groups, then taking the mean for each timestep
to get the overall all-species RLI

## Red List Status Plots

```{r RLI annual }

# * Create folders ----

rli_inputs_folder <- file.path(indicator_inputs_folder, "RLI_inputs", today)

if( !dir.exists( file.path(rli_inputs_folder) ) ) {
  dir.create( file.path(rli_inputs_folder), recursive = TRUE )
  
}

rli_outputs_folder <- file.path(indicator_outputs_folder, "RLI_outputs", today)

if( !dir.exists( file.path(rli_outputs_folder) ) ) {
  dir.create( file.path(rli_outputs_folder), recursive = TRUE )
  
}

rli_plots_folder <- file.path(indicator_plots_folder, "RLI_plots", today)

if( !dir.exists( file.path(rli_plots_folder) ) ) {
  dir.create( file.path(rli_plots_folder), recursive = TRUE )
  
}

# * Take an annual sample ----

interval <- 12

scenario_annual <- list()

# for (i in seq_along(scenario_averaged)) {

# scenario_groups <- split(scenario_averaged[[i]], 
#                          scenario_averaged[[i]]$group_id)

for (i in seq_along(scenario_smoothed_abundance)) {

 scenario_groups <- split(scenario_smoothed_abundance[[i]],
                          scenario_smoothed_abundance[[i]]$group_id)
 

  groups_annual <- list()
  
 
  for (j in seq_along(scenario_groups)) {
    
    # groups_annual[[j]] <- scenario_groups[[j]] %>% 
    #   slice(-n()) %>% 
    #   slice(which(row_number() %% interval == 0))  
    
     groups_annual[[j]] <- scenario_groups[[j]] %>% 
                           group_by(annual_time_step) %>% 
     filter(ave_abundance == first(na.omit(ave_abundance))) %>% 
       dplyr::select(-monthly_time_step, - true_extinction,
                     -abundance, -sd, - error, -lower_ci, -upper_ci) %>% 
       distinct(.) %>% 
       ungroup(.) %>% 
       group_by(group_id, annual_time_step) %>% 
       slice(1) %>% 
       ungroup(.)
    
    }
  
  groups_annual_df <- do.call(rbind, groups_annual)
  
  scenario_annual[[i]] <- groups_annual_df
  
  rm(groups_annual, groups_annual_df)
  
}

# * Assign Red List Categories ----

scenario_red_list_data <- list()

#for (i in seq_along(scenario_ab_gl_formatted)) {
for (i in seq_along(scenario_annual)) {
  
  # Get replicate data for a single scenario
  
  print(paste("Processing scenario", scenarios[[i]], sep = " "))
  
  # Split by functional group, because we calculate RLI for different
  # functional groups then aggregate later (as per Butchart etal 2010),
  # except we are using functional groups as proxies for taxa (eg mammals, birds, 
  # reptiles) used in real world RLI calcs
  
  status_inputs <- split(scenario_annual[[i]], 
                         scenario_annual[[i]]$group_id)
  
  # Make a list to hold output for each individual massbin-func-group (ie virtual spp)
  
  group_red_list_data <- list()
  
  for (j in seq_along(status_inputs)) {
    
    print(paste("Processing group", names(status_inputs)[[j]], sep = " "))
    
    group_red_list_data[[j]] <- status_inputs[[j]] %>%
      # rename(ave_abundance = abundance) %>% 
      group_by(group_id) %>%
      arrange(annual_time_step) %>%
      # calculate the difference in abundance over 10 yrs or 3 generation lengths
      # (specified by 'timeframe' column). Its okay to take the first value of 
      # timeframe bc the dataframe is grouped by group_id, and timeframe only changes
      # between and not within group_ids
      # mutate(diff = (abundance - dplyr::lag(abundance, timeframe[1]))) %>%
      mutate(diff = (ave_abundance - dplyr::lag(ave_abundance, 10))) %>%
      # Using the formula from p 35 (Complex patterns of decline) Guidelines 
      # for Using the IUCN Red List Categories and Criteria v14 August 2019 
      mutate(decline = 1 - ave_abundance/dplyr::lag(ave_abundance, 10)) %>%
      mutate(decline = ifelse(ave_abundance == 0, NA, decline)) %>% 
      # calculate the rate of change
      # mutate(decline = diff/dplyr::lag(abundance, timeframe[1])) %>% 
      # mutate(decline = diff/dplyr::lag(ave_abundance, 10)) %>%
      # mutate(prev = dplyr::lag(ave_abundance, 10)) %>% 
      # assign red list risk status based on decline 
      # Using the thresholds from p 16 Categories A2 - A4 Guidelines 
      # for Using the IUCN Red List Categories and Criteria v14 August 2019
      mutate(rl_status = ifelse(decline < 0.20, "LC",
                         ifelse(decline >= 0.20 & decline < 0.30, "NT", 
                         ifelse(decline >= 0.30 & decline < 0.50, "VU",
                         ifelse(decline >= 0.50 & decline < 0.80, "EN",
                         ifelse(decline >= 0.80, "CR",
                         ifelse(is.na(decline), "EX", "TBD"))))))) %>%
      arrange(group_id, annual_time_step) %>%
      # Replace all non-ex status with ex after first occurrence 
      # mutate(extinct = match("EX", rl_status)) %>%
      mutate(rl_status = ifelse(ave_abundance == 0, "EX", rl_status),
             rl_status = ifelse(is.na(rl_status), lag(rl_status, 1),
                                rl_status)) %>% 
      mutate(extinct = ifelse(rl_status == "EX", 1, 0)) %>% 
      # mutate(rl_status = with(., ave(rl_status, 
      #                                         FUN=maintain_ex_status)))
      #mutate(rl_status = rl_status) %>% 
      group_by(group_id)
    
  }
  
  scenario_red_list_df <- do.call(rbind, group_red_list_data)
  
  scenario_red_list_data[[i]] <- scenario_red_list_df
  
  # Save the inputs
  
  # saveRDS(scenario_red_list_df,
  #         file.path(rli_inputs_folder,
  #                   paste(today, scenarios[[i]], "replicate", j,
  #                         "RLI_input_data_monthly_smoothing.rds", sep = "_")))
  # 
  # write.csv(replicate_red_list_df,
  #           file.path(rli_inputs_folder,
  #                     paste(today, scenarios[[i]], "replicate", j,
  #                           "RLI_input_data_monthly_smoothing.csv", sep = "_")))
  
}


# * Take coarser sample ----
## Heterotrophs

sample_interval <- 1 # interval between samples in years
sample_max_timestep <- 300/sample_interval

scenario_redlist_data_sampled <- list()

for (i in seq_along(scenario_red_list_data)) {

  # Sample
   sampled <- scenario_red_list_data[[i]] %>%
     group_by(group_id) %>%
    slice(which(row_number() %% sample_interval == 0))

  # Remove groups that have no biomass in sampled years or you get weird outputs

   scenario_redlist_data_sampled[[i]] <- sampled %>%
           #rename(abundance = ave_abundance) %>%
           group_by(group_id) %>%
           mutate(total_abundance = sum(ave_abundance, na.rm = TRUE),
                  exists = ifelse(total_abundance == 0 , FALSE, TRUE)) %>%
           filter(exists == TRUE)
}

# * Get proportion extinct ----

scenario_extinctions <- list()
scenario_rl_status_plots <- list()

for (i in seq_along(scenario_redlist_data_sampled)) {
  
  scenario_extinctions[[i]] <- scenario_redlist_data_sampled[[i]] %>% 
          group_by(annual_time_step, rl_status) %>% 
          filter(rl_status != is.na(rl_status)) %>% 
          summarise(test = n())
  
  scenario_rl_status_plots[[i]] <- ggplot(scenario_extinctions[[i]], 
                                          aes(x = annual_time_step, 
                                              y = test, 
                                              fill = rl_status)) +
    geom_bar(position = "stack", stat = "identity") +
    scale_fill_viridis_d() +
    labs(title = scenarios[[i]])
  
  # ggsave(file.path(rli_plots_folder, paste(today, scenarios[[i]], 
  #                                          "red_list_status.png",
  #                                                sep = "_")),
  #        scenario_rl_status_plots[[i]],  device = "png")
  
}

scenario_rl_status_plots[[1]]
scenario_rl_status_plots[[2]]
scenario_rl_status_plots[[3]]
scenario_rl_status_plots[[4]]

```

## RLI Plots

Blue points are the relative abundance of the harvested group for that scenario

```{r RLI annual plots}

# RLI by individual functional groups

scenario_fg_rli_outputs <- list()

for (i in seq_along(scenario_redlist_data_sampled)) {
  
  scenario_fg_rli_outputs[[i]] <- calculate_red_list_index(
    scenario_redlist_data_sampled[[i]], numboots, ci = FALSE) %>%
    mutate(scenario = scenarios[[i]]) 
  
}

# Mean RLI aggregated across groups

scenario_rli_outputs <- list()

for (i in seq_along(scenario_fg_rli_outputs)) {
  
  if ("ci_lower" %in% names(scenario_fg_rli_outputs[[i]])) {
    
    scenario_rli_outputs[[i]] <- scenario_fg_rli_outputs[[i]] %>%
      group_by(annual_time_step) %>%
      summarise(indicator_score = mean(indicator_score),
                ci_lower = mean(ci_lower),
                ci_upper = mean(ci_upper)) %>%
      mutate(indicator = "RLI",
             replicate = j)
  } else {
    
    scenario_rli_outputs[[i]] <- scenario_fg_rli_outputs[[i]] %>%
      group_by(annual_time_step) %>%
      summarise(indicator_score = mean(indicator_score)) %>%
      mutate(indicator = "RLI",
             replicate = j)
  }
  
}



# * Get the mean abundance of all groups in each time step

scenario_mean_abundance <- list()

for (i in seq_along(scenario_redlist_data_sampled)) {

  scenario_mean_abundance[[i]] <- scenario_redlist_data_sampled[[i]] %>% 
  ungroup() %>% 
  group_by(annual_time_step) %>% 
  mutate(mean_group_abundance = mean(ave_abundance, na.rm = TRUE)) %>% 
  ungroup() %>% 
  dplyr::select(annual_time_step, mean_group_abundance) %>% 
  distinct(.)

  scenario_mean_abundance[[i]]$standardised_abundance <- range01(scenario_mean_abundance[[i]]$mean_group_abundance)  

}



# * Plot RLI ----

## By functional group

scenario_fg_rli_plots <- list()

for (i in seq_along(scenario_fg_rli_outputs)) {
  
  scenario_fg_rli_plots[[i]] <-  plot_red_list_index_by_group(
    scenario_fg_rli_outputs[[i]],
    impact_start,
    impact_end,
    ci = FALSE) +
    labs(title = scenarios[[i]])
  
  # ggsave(file.path(rli_plots_folder, paste(today, scenarios[[i]], 
  #                                          "RLI_by_functional_group_reps_averaged.png",
  #                                          sep = "_")),
  #        scenario_fg_rli_plots[[i]],  device = "png")
  
}

# RLI with all functional groups aggregated
# i.e. mean of each 'taxa' RLI as per Butchart et al (2010) 'Indicators of
# recent declines'

scenario_rli_plots <- list()

for (i in seq_along(scenario_rli_outputs)) {
  
  
  scenario_rli_plots[[i]] <- plot_red_list_index(scenario_rli_outputs[[i]],
                                                 impact_start, 
                                                 impact_end,
                                                 ci = FALSE,
                                                 scenario_harvested[[i]]) +
                                labs(title = scenarios[[i]])
  
  # ggsave(file.path(rli_plots_folder, paste(today, scenarios[[i]],
  #                                          "RLI_aggregated_averaged.png",
  #                                          sep = "_")),
  #        scenario_rli_plots[[i]],  device = "png")
  
}

scenario_rli_plots[[1]]
scenario_rli_plots[[2]]
scenario_rli_plots[[3]]
scenario_rli_plots[[4]]
```

# RED LIST INDEX ANNUAL V2 

Lumping all species together to calculate RLI first up, rather than calculating 
by functional group then taking the mean

``` {r RLI annual v2}

# * Calculate RLI ----

# RLI across all groups

scenario_all_rli_outputs <- list()

for (i in seq_along(scenario_redlist_data_sampled)) {
  
  scenario_all_rli_outputs[[i]] <- calculate_red_list_index2(
    scenario_redlist_data_sampled[[i]], numboots, ci = FALSE) %>%
    mutate(scenario = scenarios[[i]]) 
  
}

# * Plot RLI ----

# Using V2

scenario_all_rli_plots <- list()

for (i in seq_along(scenario_all_rli_outputs)) {
  
  scenario_all_rli_plots[[i]] <- plot_red_list_index(scenario_all_rli_outputs[[i]],
                                                     impact_start, 
                                                     impact_end,
                                                     ci = FALSE,
                                                 scenario_harvested[[i]]) +
    labs(title = scenarios[[i]])
  
  # ggsave(file.path(rli_plots_folder, paste(today, scenarios[[i]],
  #                                          "RLI_aggregated_averaged_annual_v2.png",
  #                                          sep = "_")),
  #        scenario_all_rli_plots[[i]],  device = "png")
  
}

scenario_all_rli_plots[[1]]
scenario_all_rli_plots[[2]]
scenario_all_rli_plots[[3]]
scenario_all_rli_plots[[4]]

```

# RED LIST INDEX ANNUAL V3 

Combining all species as above, but only including species larger than 10kg

```{r RLI annual v3}

# * Calculate RLI ----

# RLI with only large species

scenario_large_spp_rli_outputs <- list()

for (i in seq_along(scenario_redlist_data_sampled)) {
  
  large_spp <- scenario_redlist_data_sampled[[i]] %>% 
              filter(mass_lower > 10000)
  
  scenario_large_spp_rli_outputs[[i]] <- calculate_red_list_index2(
    large_spp, numboots, ci = FALSE) %>%
    mutate(scenario = scenarios[[i]]) 
  
  rm(large_spp)
  
}

# * Plot RLI ----

# Using V2

scenario_large_spp_rli_plots <- list()

for (i in seq_along(scenario_large_spp_rli_outputs)) {
  
  scenario_large_spp_rli_plots[[i]] <- plot_red_list_index(scenario_large_spp_rli_outputs[[i]],
                                                     impact_start, 
                                                     impact_end,
                                                     ci = FALSE,
                                                 scenario_harvested[[i]]) +
    labs(title = scenarios[[i]])
  
  # ggsave(file.path(rli_plots_folder, paste(today, scenarios[[i]],
  #                                          "RLI_aggregated_averaged_annual_lgspp_v3.png",
  #                                          sep = "_")),
  #        scenario_large_spp_rli_plots[[i]],  device = "png")
  
}

scenario_large_spp_rli_plots[[1]]
scenario_large_spp_rli_plots[[2]]
scenario_large_spp_rli_plots[[3]]
scenario_large_spp_rli_plots[[4]]
```

# RED LIST INDEX 5 YRS V1

Using data where the Red List status of each species has already been calculated
using annual data, and sampling the status of each species in the first year
of each five year period. 

Calculated by functional group then averaged to get overall all-species RLI

## Red List Status Plots

```{r RLI 5yrs v1}

# * Take coarser sample ----
## Heterotrophs

sample_interval <- 5 # interval between samples in years
sample_max_timestep <- 300/sample_interval

scenario_redlist_data_sampled_5yr <- list()

for (i in seq_along(scenario_red_list_data)) {
  
  # Sample
  
  set <- seq(5,295,5)
 
  scenario_redlist_data_sampled_5yr[[i]] <- scenario_red_list_data[[i]] %>% 
    group_by(group_id) %>%
    #Calculate how many timesteps of data available for that species
    mutate(n_timesteps = n()) %>% 
    #Add a 5 yr interval column for sampling
    mutate(annual_time_step = rep(set, each = sample_interval,
                          length.out = n_timesteps[1])) %>% 
    # Group by species and interval
    group_by(group_id, annual_time_step) %>%
    # Take the first observation
    slice(1)
  
  # Remove groups that have no biomass in sampled years or you get weird outputs
  
  # scenario_redlist_data_sampled_5yr[[i]] <- sampled %>% 
  #   rename(abundance = ave_abundance) %>% 
  #   group_by(group_id) %>% 
  #   mutate(total_abundance = sum(abundance, na.rm = TRUE),
  #          exists = ifelse(total_abundance == 0 , FALSE, TRUE)) %>% 
  #   filter(exists == TRUE)
  
}



# * Get proportion extinct ----

test2 <- scenario_redlist_data_sampled[[1]] %>% 
         group_by(annual_time_step) %>% 
         summarise(x = n())

test <- scenario_redlist_data_sampled_5yr[[1]] %>% 
        group_by(annual_time_step) %>% 
        summarise(x = n())


scenario_extinctions_5yr <- list()
scenario_rl_status_plots_5yr <- list()

for (i in seq_along(scenario_redlist_data_sampled_5yr)) {
  
  scenario_extinctions_5yr[[i]] <- scenario_redlist_data_sampled_5yr[[i]] %>% 
    group_by(annual_time_step, rl_status) %>% 
    filter(rl_status != is.na(rl_status)) %>% 
    summarise(test = n())
  
  scenario_rl_status_plots_5yr[[i]] <- ggplot(scenario_extinctions_5yr[[i]], 
                                          aes(x = annual_time_step, 
                                              y = test, 
                                              fill = rl_status)) +
    geom_bar(position = "stack", stat = "identity") +
    scale_fill_viridis_d() +
    labs(title = scenarios[[i]])
  
  # ggsave(file.path(rli_plots_folder, paste(today, scenarios[[i]], 
  #                                          "red_list_status.png",
  #                                          sep = "_")),
  #        scenario_rl_status_plots_5yr[[i]],  device = "png")
  
}

scenario_rl_status_plots_5yr[[1]]
scenario_rl_status_plots_5yr[[2]]
scenario_rl_status_plots_5yr[[3]]
scenario_rl_status_plots_5yr[[4]]

```

## RLI Plots

```{r RLI 5yrs v1 index plots}
# RLI by individual functional groups

scenario_fg_rli_outputs_5yr <- list()

for (i in seq_along(scenario_redlist_data_sampled_5yr)) {
  
  scenario_fg_rli_outputs_5yr[[i]] <- calculate_red_list_index(
    scenario_redlist_data_sampled_5yr[[i]], numboots, ci = FALSE) %>%
    mutate(scenario = scenarios[[i]]) 
  
}

# Mean RLI aggregated across groups

scenario_rli_outputs_5yr <- list()

for (i in seq_along(scenario_fg_rli_outputs_5yr)) {
  
  if ("ci_lower" %in% names(scenario_fg_rli_outputs_5yr[[i]])) {
    
    scenario_rli_outputs_5yr[[i]] <- scenario_fg_rli_outputs_5yr[[i]] %>%
      group_by(annual_time_step) %>%
      summarise(indicator_score = mean(indicator_score),
                ci_lower = mean(ci_lower),
                ci_upper = mean(ci_upper)) %>%
      mutate(indicator = "RLI",
             replicate = j)
  } else {
    
    scenario_rli_outputs_5yr[[i]] <- scenario_fg_rli_outputs_5yr[[i]] %>%
      group_by(annual_time_step) %>%
      summarise(indicator_score = mean(indicator_score)) %>%
      mutate(indicator = "RLI",
             replicate = j)
  }
  
}

# * Plot RLI ----

## By functional group

scenario_rli_plots_fg_5yr <- list()

for (i in seq_along(scenario_fg_rli_outputs_5yr)) {
  
  scenario_rli_plots_fg_5yr[[i]] <-  plot_red_list_index_by_group(
    scenario_fg_rli_outputs_5yr[[i]],
    impact_start,
    impact_end,
    ci = FALSE) +
    labs(title = scenarios[[i]])
  
  # ggsave(file.path(rli_plots_folder, paste(today, scenarios[[i]], 
  #                                          "RLI_by_functional_group_reps_averaged_5yr.png",
  #                                          sep = "_")),
  #        scenario_rli_outputs_5yr[[i]],  device = "png")
  
}

# scenario_rli_plots_fg_5yr[[1]]
# scenario_rli_plots_fg_5yr[[2]]
# scenario_rli_plots_fg_5yr[[3]]
# scenario_rli_plots_fg_5yr[[4]]
```

```{r RLI 5 yrs V1 status plots}

scenario_rli_plots_5yr <- list()

for (i in seq_along(scenario_rli_outputs_5yr)) {
  
  
  scenario_rli_plots_5yr[[i]] <- plot_red_list_index(scenario_rli_outputs_5yr[[i]],
                                                 impact_start, 
                                                 impact_end,
                                                 ci = FALSE,
                                                 scenario_harvested[[i]]) +
    labs(title = scenarios[[i]])
  
  # ggsave(file.path(rli_plots_folder, paste(today, scenarios[[i]], 
  #                                          "RLI_aggregated_averaged_5yr.png",
  #                                          sep = "_")),
  #        scenario_rli_plots_5yr[[i]],  device = "png")
  
}

scenario_rli_plots_5yr[[1]]
scenario_rli_plots_5yr[[2]]
scenario_rli_plots_5yr[[3]]
scenario_rli_plots_5yr[[4]]
```

# RED LIST INDEX 5 YRS V2 

Assign the red list categories after sampling instead of before

## Red List Status Plots

```{r RLI 5yrs v2 status plots}

## Referring to the thresholds quote under Criterion A, Reason 1 (declines
## are the result of reversible pressures) according to:
## https://portals.iucn.org/library/sites/library/files/documents/RL-2001-001-2nd.pdf


# * Assign Red List Categories ----

scenario_red_list_data_v2 <- list()

#for (i in seq_along(scenario_ab_gl_formatted)) {
for (i in seq_along(scenario_redlist_data_sampled_5yr)) {
  
  # Get replicate data for a single scenario
  
  print(paste("Processing scenario", scenarios[[i]], sep = " "))
  
  # Split by functional group, because we calculate RLI for different
  # functional groups then aggregate later (as per Butchart etal 2010),
  # except we are using functional groups as proxies for taxa (eg mammals, birds, 
  # reptiles) used in real world RLI calcs
  
  status_inputs <- split(scenario_redlist_data_sampled_5yr[[i]], 
                         scenario_redlist_data_sampled_5yr[[i]]$group_id)
  
  # Make a list to hold output for each individual massbin-func-group (ie virtual spp)
  
  group_red_list_data <- list()
  
  for (j in seq_along(status_inputs)) {
    
    print(paste("Processing group", names(status_inputs)[[j]], sep = " "))
    
    group_red_list_data[[j]] <- status_inputs[[j]] %>%
      #rename(ave_abundance = abundance) %>% 
      group_by(group_id) %>%
      arrange(annual_time_step) %>%
      # calculate the difference in abundance over 10 yrs or 3 generation lengths
      # (specified by 'timeframe' column). Its okay to take the first value of 
      # timeframe bc the dataframe is grouped by group_id, and timeframe only changes
      # between and not within group_ids
      # mutate(diff = (abundance - dplyr::lag(abundance, timeframe[1]))) %>%
      mutate(diff = (ave_abundance - dplyr::lag(ave_abundance, 2))) %>%
      # Using the formula from p 35 (Complex patterns of decline) Guidelines 
      # for Using the IUCN Red List Categories and Criteria v14 August 2019 
      mutate(decline = 1 - ave_abundance/dplyr::lag(ave_abundance, 2)) %>%
      mutate(decline = ifelse(ave_abundance == 0, NA, decline)) %>% 
      # calculate the rate of change
      # mutate(decline = diff/dplyr::lag(abundance, timeframe[1])) %>% 
      # mutate(decline = diff/dplyr::lag(ave_abundance, 10)) %>%
      # mutate(prev = dplyr::lag(ave_abundance, 10)) %>% 
      # assign red list risk status based on decline 
      # Using the thresholds from p 16 Categories A2 - A4 Guidelines 
      # for Using the IUCN Red List Categories and Criteria v14 August 2019
      mutate(rl_status = ifelse(decline < 0.20, "LC",
                                ifelse(decline >= 0.20 & decline < 0.30, "NT", 
                                       ifelse(decline >= 0.30 & decline < 0.50, "VU",
                                              ifelse(decline >= 0.50 & decline < 0.80, "EN",
                                                     ifelse(decline >= 0.80, "CR",
                                                            ifelse(is.na(decline), "EX", "TBD"))))))) %>%
      arrange(group_id, annual_time_step) %>%
      # Replace all non-ex status with ex after first occurrence 
      # mutate(extinct = match("EX", rl_status)) %>%
      mutate(rl_status = ifelse(ave_abundance == 0, "EX", rl_status)) %>% 
      mutate(extinct = ifelse(rl_status == "EX", 1, 0)) %>% 
      # mutate(rl_status = with(., ave(rl_status, 
      #                                         FUN=maintain_ex_status)))
      #mutate(rl_status = rl_status) %>% 
      group_by(group_id)
    
  }
  
  scenario_red_list_df <- do.call(rbind, group_red_list_data)
  
  scenario_red_list_data_v2[[i]] <- scenario_red_list_df
  
  rm(scenario_red_list_df, group_red_list_data, status_inputs)
  
  # Save the inputs
  
  # saveRDS(scenario_red_list_df,
  #         file.path(rli_inputs_folder,
  #                   paste(today, scenarios[[i]], "replicate", j,
  #                         "RLI_input_data_monthly_smoothing.rds", sep = "_")))
  # 
  # write.csv(replicate_red_list_df,
  #           file.path(rli_inputs_folder,
  #                     paste(today, scenarios[[i]], "replicate", j,
  #                           "RLI_input_data_monthly_smoothing.csv", sep = "_")))
  
}


# Have a quick look at the outputs

# * Get proportion extinct ----

scenario_extinctions <- list()
scenario_rl_status_plots <- list()

for (i in seq_along(scenario_red_list_data_v2)) {
  
  scenario_extinctions[[i]] <- scenario_red_list_data_v2[[i]] %>% 
    group_by(annual_time_step, rl_status) %>% 
    filter(rl_status != is.na(rl_status)) %>% 
    summarise(test = n())
  
  scenario_rl_status_plots[[i]] <- ggplot(scenario_extinctions[[i]], 
                                          aes(x = annual_time_step, 
                                              y = test, 
                                              fill = rl_status)) +
    geom_bar(position = "stack", stat = "identity") +
    scale_fill_viridis_d() +
    labs(title = scenarios[[i]])
  
  # ggsave(file.path(rli_plots_folder, paste(today, scenarios[[i]], 
  #                                          "red_list_status.png",
  #                                          sep = "_")),
  #        scenario_rl_status_plots[[i]],  device = "png")
  
}

scenario_rl_status_plots[[1]]
scenario_rl_status_plots[[2]]
scenario_rl_status_plots[[3]]
scenario_rl_status_plots[[4]]

```

## RLI Plots 

```{r RLI 5yr plots v2}

# RLI by individual functional groups

scenario_fg_rli_outputs_v2 <- list()

for (i in seq_along(scenario_red_list_data_v2)) {
  
  scenario_fg_rli_outputs_v2[[i]] <- calculate_red_list_index(
    scenario_red_list_data_v2[[i]], numboots, ci = FALSE) %>%
    mutate(scenario = scenarios[[i]]) 
  
}

# RLI across all groups

scenario_all_rli_outputs_v2 <- list()

for (i in seq_along(scenario_red_list_data_v2)) {
  
  scenario_all_rli_outputs_v2[[i]] <- calculate_red_list_index2(
    scenario_red_list_data_v2[[i]], numboots, ci = FALSE) %>%
    mutate(scenario = scenarios[[i]]) 
  
}

# * Plot RLI ----

# Using V2

scenario_all_rli_plots_v2 <- list()

for (i in seq_along(scenario_all_rli_outputs_v2)) {
  
  scenario_all_rli_plots_v2[[i]] <- plot_red_list_index(scenario_all_rli_outputs_v2[[i]],
                                                 impact_start, 
                                                 impact_end,
                                                 ci = FALSE,
                                                 scenario_harvested[[i]]) +
    labs(title = scenarios[[i]])
  
  # ggsave(file.path(rli_plots_folder, paste(today, scenarios[[i]],
  #                                          "RLI_aggregated_averaged_5yr2.png",
  #                                          sep = "_")),
  #        scenario_all_rli_plots[[i]],  device = "png")
  
}

scenario_all_rli_plots_v2[[1]]
scenario_all_rli_plots_v2[[2]]
scenario_all_rli_plots_v2[[3]]
scenario_all_rli_plots_v2[[4]]

```

# RED LIST INDEX 5YRS V3 

RLI same as above, but with only large species (>10kg)

```{r RLI 5yrs v3 }

scenario_large_spp_rli_outputs_5yr <- list()

for (i in seq_along(scenario_redlist_data_sampled_5yr)) {
  
  large_spp <- scenario_redlist_data_sampled_5yr[[i]] %>% 
    tidylog::filter(mass_lower > 10000)
  
  scenario_large_spp_rli_outputs_5yr[[i]] <- calculate_red_list_index2(
    large_spp, numboots, ci = FALSE) %>%
    mutate(scenario = scenarios[[i]]) 
  
  rm(large_spp)
  
}

# * Plot RLI ----

# Using V2

scenario_large_spp_rli_plots_5yr <- list()

for (i in seq_along(scenario_large_spp_rli_outputs)) {
  
  scenario_large_spp_rli_plots_5yr[[i]] <- plot_red_list_index(scenario_large_spp_rli_outputs_5yr[[i]],
                                                           impact_start, 
                                                           impact_end,
                                                           ci = FALSE,
                                                 scenario_harvested[[i]]) +
    labs(title = scenarios[[i]])
  
  # ggsave(file.path(rli_plots_folder, paste(today, scenarios[[i]],
  #                                          "RLI_aggregated_averaged_5yr_lgspp_v3.png",
  #                                          sep = "_")),
  #        scenario_large_spp_rli_plots_5yr[[i]],  device = "png")
  
}

scenario_large_spp_rli_plots_5yr[[1]]
scenario_large_spp_rli_plots_5yr[[2]]
scenario_large_spp_rli_plots_5yr[[3]]
scenario_large_spp_rli_plots_5yr[[4]]

```
